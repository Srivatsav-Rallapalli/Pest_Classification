{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e345ae6-8c49-4026-a95d-813f60cfefc4",
   "metadata": {},
   "source": [
    "# Business Problem\n",
    "\n",
    "The Agricultural Pests Image Dataset is a collection of images of 12 different type of agricultural pests, namely Ants, Bees, Beetle, Catterpillar, Earthworms, Earwig, Grasshopper, Moth, Slug, Snail, Wasp, Weevil. This Dataset is for the Development and Evaluation of Machine Learning models for Pest Detection and Classification in Agriculture Settings. With 12 classes of pests, the Dataset provides a diverse range of images that cover a variety of shapes, colors, and sizes, making it suitable for training and testing algorithms to detect and classify pests in various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55bc72fa-8030-4797-8225-6c22ee1e17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary Libraries\n",
    "\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5777935c-f535-4f39-af50-77aac660d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ImageDataGenerator.\n",
    "# configure random transformations and normalize operations to be done on image data during training.\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a4534d-7d65-4d0e-8a56-886a76ac85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Train Data\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1/255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c5dd8b-d922-4e7e-8471-6886906571a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4392 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating the Test Images set\n",
    "\n",
    "train = train_data.flow_from_directory('Train',\n",
    "                                       target_size=(150,150),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72354e7d-477f-4f23-a6e1-e6b9d985c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ants': 0,\n",
       " 'bees': 1,\n",
       " 'beetle': 2,\n",
       " 'catterpillar': 3,\n",
       " 'earthworms': 4,\n",
       " 'earwig': 5,\n",
       " 'grasshopper': 6,\n",
       " 'moth': 7,\n",
       " 'slug': 8,\n",
       " 'snail': 9,\n",
       " 'wasp': 10,\n",
       " 'weevil': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indices of the Classes\n",
    "\n",
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f2f96ad-11be-4ba9-9a97-c6c1cd69b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1102 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating and Creating the Test Images set\n",
    "\n",
    "test_data = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "test = test_data.flow_from_directory('Test',\n",
    "                                     target_size=(150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca0e4a-6aa2-4d04-a1de-81e287052f41",
   "metadata": {},
   "source": [
    "**Modelling the Convolution Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82497885-5128-4af1-a305-f68b251fb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential used to group the stacks of layers into the model. \n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d393d092-e52e-42f8-9564-76d3b9564df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Apply a convolutional Neural Network that applies a filter to 2D input data to produce a tensor of output.\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(input_shape=[150,150,3],\n",
    "                     filters=32,kernel_size=3,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f96306d-fae3-4bb8-b505-cbe0ac393ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the spatial dimensions of an input volume\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a90a68d9-0591-43a7-87e0-bc3ac7449cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data into one dimensional array\n",
    "\n",
    "from keras.layers import Flatten\n",
    "\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b780cd1-e465-42a1-8690-3b481e8f77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Hidden layer with 300 neurons\n",
    "classifier.add(Dense(units=300,activation='relu'))\n",
    "\n",
    "# Output Layer with 1 neuuron\n",
    "classifier.add(Dense(units=12,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c42a2ba-1359-4da7-bb9f-a5265c55a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test the model\n",
    "\n",
    "classifier.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fe4d57f-f71b-41a1-9159-61e79e60cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1042 - loss: 7.4992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - accuracy: 0.1043 - loss: 7.4734 - val_accuracy: 0.1706 - val_loss: 2.3972\n",
      "Epoch 2/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.1897 - loss: 2.3655 - val_accuracy: 0.2432 - val_loss: 2.2345\n",
      "Epoch 3/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 1s/step - accuracy: 0.3196 - loss: 2.0780 - val_accuracy: 0.2976 - val_loss: 2.1822\n",
      "Epoch 4/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.3747 - loss: 1.8615 - val_accuracy: 0.3448 - val_loss: 2.0882\n",
      "Epoch 5/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.4449 - loss: 1.6782 - val_accuracy: 0.3276 - val_loss: 2.0976\n",
      "Epoch 6/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.4875 - loss: 1.5740 - val_accuracy: 0.3376 - val_loss: 2.0687\n",
      "Epoch 7/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5320 - loss: 1.4346 - val_accuracy: 0.3303 - val_loss: 2.2491\n",
      "Epoch 8/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5638 - loss: 1.3198 - val_accuracy: 0.3539 - val_loss: 2.2800\n",
      "Epoch 9/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6254 - loss: 1.1836 - val_accuracy: 0.3285 - val_loss: 2.3032\n",
      "Epoch 10/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6564 - loss: 1.0833 - val_accuracy: 0.3639 - val_loss: 2.3265\n",
      "Epoch 11/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6929 - loss: 0.9526 - val_accuracy: 0.3457 - val_loss: 2.4774\n",
      "Epoch 12/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.7221 - loss: 0.8824 - val_accuracy: 0.3566 - val_loss: 2.5983\n",
      "Epoch 13/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.7622 - loss: 0.7480 - val_accuracy: 0.3539 - val_loss: 2.5358\n",
      "Epoch 14/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.7643 - loss: 0.7558 - val_accuracy: 0.3575 - val_loss: 2.5883\n",
      "Epoch 15/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.7999 - loss: 0.6429 - val_accuracy: 0.3584 - val_loss: 2.8717\n",
      "Epoch 16/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8185 - loss: 0.5850 - val_accuracy: 0.3503 - val_loss: 3.0788\n",
      "Epoch 17/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 1s/step - accuracy: 0.8397 - loss: 0.5362 - val_accuracy: 0.3521 - val_loss: 3.0996\n",
      "Epoch 18/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8626 - loss: 0.4571 - val_accuracy: 0.3639 - val_loss: 2.9668\n",
      "Epoch 19/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.8716 - loss: 0.4211 - val_accuracy: 0.3566 - val_loss: 3.2968\n",
      "Epoch 20/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.8875 - loss: 0.3832 - val_accuracy: 0.3684 - val_loss: 3.2204\n",
      "Epoch 21/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.8970 - loss: 0.3535 - val_accuracy: 0.3566 - val_loss: 3.5718\n",
      "Epoch 22/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.9000 - loss: 0.3388 - val_accuracy: 0.3303 - val_loss: 3.7993\n",
      "Epoch 23/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9095 - loss: 0.3054 - val_accuracy: 0.3748 - val_loss: 3.5149\n",
      "Epoch 24/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.9197 - loss: 0.2702 - val_accuracy: 0.3721 - val_loss: 3.5540\n",
      "Epoch 25/25\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.9220 - loss: 0.2850 - val_accuracy: 0.3866 - val_loss: 3.6093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b613d1af60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with Train and Test\n",
    "\n",
    "classifier.fit(x=train,validation_data=test,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2885a31-3072-415b-84b5-a947a0b8e957",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- make a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "562de4f7-655d-4c05-952f-b8a4a19b4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e9c9d3-f544-42b5-9026-c1d1004cc361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Data\n",
    "img = Image.open('pred/download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfef33f5-b3f1-4358-8ef5-69843effb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((150,150))\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c172d1-c2a9-4a95-ab22-0577a75dfb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Ant\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "result = classifier.predict(img)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    print('Bees')\n",
    "elif result[0][0] == 2:\n",
    "    print('Beetle')\n",
    "elif result[0][0] == 3:\n",
    "    print('Catterpillar')\n",
    "elif result[0][0] == 4:\n",
    "    print('Earthworm')\n",
    "elif result[0][0] == 5:\n",
    "    print('Earwig')\n",
    "elif result[0][0] == 6:\n",
    "    print('Grasshopper')\n",
    "elif result[0][0] == 7:\n",
    "    print('Moth')\n",
    "elif result[0][0] == 8:\n",
    "    print('Slug')\n",
    "elif result[0][0] == 9:\n",
    "    print('Snail')\n",
    "elif result[0][0] == 10:\n",
    "    print('Wasp')\n",
    "elif result[0][0] == 11:\n",
    "    print('Weevil')\n",
    "else:\n",
    "    print('Ant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02fd1d4-39ac-4910-89e5-24ad7aed2902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
